Average absolute difference between LIME and feature importance scores.
Scores were scaled to [0,1] (min max scaling)
LIME globally approximated feature importance by sampling 50 molecules, doing LIME on each and aggregating the results (mean).
Bits found by both methods were compared. If there was no bit on the other side of the comparison, a value of 0 was compared to instead.
Lower = better.
A kind of baseline: 0.333 - expected distance between 2 random points on [0,1] interval.

herg: 0.3455960086410675
cyp: 0.5027919427276933
synthetic: 0.17104930345530223

These results suggest there is a big difference between LIME and feature importance scores.
We can conclude that LIME is performing weakly, as feature importance scores are tied to training the model.