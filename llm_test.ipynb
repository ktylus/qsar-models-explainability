{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "with open(\"openai/api_key.txt\") as f:\n",
    "    api_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/iupacs_saliency_map.json\", \"r\") as f:\n",
    "    iupacs_saliency_map = json.load(f)\n",
    "\n",
    "with open(\"results/iupacs_grad_cam.json\", \"r\") as f:\n",
    "    iupacs_grad_cam = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_cam_results = {}\n",
    "saliency_map_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_targets = {\n",
    "    \"herg\": \"HERG toxicity\",\n",
    "    \"pampa\": \"PAMPA permeability\",\n",
    "    \"cyp\": \"CYP2A4 inhibition\"\n",
    "}\n",
    "\n",
    "for dataset_name in (\"herg\", \"pampa\", \"cyp\"):\n",
    "    total_result = []\n",
    "    for i in range(len(iupacs_grad_cam[dataset_name])):\n",
    "        result = []\n",
    "        for iupac in iupacs_grad_cam[dataset_name][i]:\n",
    "            client = OpenAI(api_key=api_key)\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a helpful assistant.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"\"\"\n",
    "                        Rate the molecule fragment with the IUPAC name: {iupac} with respect to its impact on the {prompt_targets[dataset_name]}.\n",
    "                        Output an integer score between 1 and 10, where 1 means the component has a very low impact on the {prompt_targets[dataset_name]}\n",
    "                        and 10 means the component has a very high impact on the {prompt_targets[dataset_name]}.\n",
    "                        Do not output anything besides the score.\n",
    "                        \"\"\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            result.append(completion.choices[0].message.content)\n",
    "        total_result.append(result)\n",
    "    grad_cam_results[dataset_name] = total_result\n",
    "\n",
    "for dataset_name in (\"herg\", \"pampa\", \"cyp\"):\n",
    "    total_result = []\n",
    "    for i in range(len(iupacs_saliency_map[dataset_name])):\n",
    "        result = []\n",
    "        for iupac in iupacs_saliency_map[dataset_name][i]:\n",
    "            client = OpenAI(api_key=api_key)\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a helpful assistant.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"\"\"\n",
    "                        Rate the molecule fragment with the IUPAC name: {iupac} with respect to its impact on the {prompt_targets[dataset_name]}.\n",
    "                        Output an integer score between 1 and 10, where 1 means the component has a very low impact on the {prompt_targets[dataset_name]}\n",
    "                        and 10 means the component has a very high impact on the {prompt_targets[dataset_name]}.\n",
    "                        Do not output anything besides the score.\n",
    "                        \"\"\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            result.append(completion.choices[0].message.content)\n",
    "        total_result.append(result)\n",
    "    saliency_map_results[dataset_name] = total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3', '5', '5', '3', '5', '7', '3', '7'],\n",
       " ['5', '4', '5', '3', '5', '5', '5', '3', '5'],\n",
       " ['4', '5', '7', '7', '4', '4', '6', '4', '5'],\n",
       " ['5', '6', '7', '3', '5', '3', '8', '3', '5', '5'],\n",
       " ['8', '3', '6', '4', '4', '5', '5', '5', '6', '6'],\n",
       " ['2', '5', '7', '3', '4', '4', '6', '3']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saliency_map_results[\"pampa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/llm_grad_cam_results.json\", \"w\") as f:\n",
    "    json.dump(grad_cam_results, f)\n",
    "\n",
    "with open(\"results/llm_saliency_map_results.json\", \"w\") as f:\n",
    "    json.dump(saliency_map_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
